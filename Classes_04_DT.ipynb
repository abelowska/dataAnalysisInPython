{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelowska/dataPy/blob/main/Classes_04_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UM_-fA16Wx0"
      },
      "source": [
        "# Nonlinear regressors: Decision Tree\n",
        "\n",
        "Today we are going to use our own dataset.\n",
        "\n",
        "The dataset consists of data on **personality** (Big Five assesed with [NEO FFI](https://sjdm.org/dmidi/NEO-FFI.html)) and **cognitive religious belief styles** ([The Post-Critical Belief Scale](https://theo.kuleuven.be/apps/press/ecsi/files/2019/03/4.-Pollefeyt-Bouwens-PCB-Melb-Vict-for-dummies-EN.pdf)) from 342 individuals. We will be interested wheter it is possible to predict  cognitive religious belief style from personality traits. Make sure you downloaded the dataset from github repository [here](https://github.com/abelowska/dataPy/blob/main/data_neo-ffi_religion.csv) and uploaded it into Colabolatory *Files*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q6dBZxA7WVj"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEyKd5686Pt8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"deep\")\n",
        "\n",
        "import io\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import set_config\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "from sklearn.metrics import PredictionErrorDisplay, median_absolute_error\n",
        "from sklearn.preprocessing import power_transform\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Hsi48QOGpX"
      },
      "outputs": [],
      "source": [
        "# constans\n",
        "test_size=0.2\n",
        "random_state=42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(y_true, y_pred):\n",
        "  '''\n",
        "  Helper function for printing scores.\n",
        "\n",
        "  Parameters:\n",
        "  y_true: ndarray of y values from original dataset.\n",
        "  y_pred: ndarray of y values predicted with given model.\n",
        "\n",
        "  Return:\n",
        "  dictionary object that consists of R2 and median absolute error scores.\n",
        "\n",
        "  '''\n",
        "  return {\n",
        "        \"R2\": f\"{r2_score(y_true, y_pred):.3f}\",\n",
        "        \"MedianAE\": f\"{median_absolute_error(y_true, y_pred):.3f}\",\n",
        "}"
      ],
      "metadata": {
        "id": "weAtuf398bDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction_error(y_test, y_pred, scores):\n",
        "  _, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "  y_test = y_test.to_numpy() if isinstance(y_test, pd.DataFrame) else y_test\n",
        "\n",
        "  display_ = PredictionErrorDisplay.from_predictions(\n",
        "      y_test,\n",
        "      y_pred,\n",
        "      kind=\"actual_vs_predicted\",\n",
        "      ax=ax,\n",
        "      scatter_kwargs={\"alpha\": 0.5}\n",
        "  )\n",
        "\n",
        "  ax.set_title(\"Linear model\")\n",
        "  for name, score in scores.items():\n",
        "      ax.plot([], [], \" \", label=f\"{name}: {score}\")\n",
        "  ax.legend(loc=\"upper left\")\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "DAdHKvE7-C_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C40f350QVvNb"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEsePeoHLXCj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data_neo-ffi_religion.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the dataset"
      ],
      "metadata": {
        "id": "2_s0HU7J6BRu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ado_rVXzyc"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees"
      ],
      "metadata": {
        "id": "dcf6CPqORd4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to create our model\n",
        "\n",
        "*Orthodoxy ~ Extraversion + Agreeableness + Openness + Neuroticism + Conscientiousness*\n",
        "\n",
        "using decision trees and compare this model to linear regression and KNN. Lets's take a look on the simples DT model."
      ],
      "metadata": {
        "id": "tynD0O5-Rjpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[[\n",
        "    'Extraversion',\n",
        "    'Agreeableness',\n",
        "    'Conscientiousness',\n",
        "    'Openness',\n",
        "    'Neuroticism']]\n",
        "\n",
        "y = df[['Orthodoxy']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# create object of DT estimator\n",
        "dt = DecisionTreeRegressor()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "scores = compute_score(y_test, y_pred)\n",
        "scores"
      ],
      "metadata": {
        "id": "Srjm01AFRkQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_error(y_test, y_pred, scores)"
      ],
      "metadata": {
        "id": "mpXCBVAJSa0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oops! Something is clearly wrong. Do you have any idea what happened?**"
      ],
      "metadata": {
        "id": "lzEpx_InSfhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3\n",
        "\n",
        "Try to plot the distribution of y. Does it look like a normal distribution, or something else?\n",
        "\n",
        "Decision Trees (DTs) try to find the best dividing lines for the data by assessing the quality of these divisions using cost functions (which are based on the data variance). We need to \"fix\" our variances to make them more comparable, so we can realize the full potential of decision trees.\n",
        "\n",
        "Create the model with the DT estimator, but before fitting, transform y to have a more Gaussian-like distribution. You can:\n",
        "\n",
        "1.   Apply an appropriate transformation to y manually.\n",
        "2.   Use built-in methods such as the [`power_transform()`](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.power_transform.html) function."
      ],
      "metadata": {
        "id": "mw5MirNpVCqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "hSY2pWnvRkUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_error(y_test, y_pred, scores)"
      ],
      "metadata": {
        "id": "bcEQrQYkRkep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Exercise 3.1)\n",
        "\n",
        "Decision trees have a lot of adjustable parameters. Especially interesting are: `criterion`, `max_depth`, `min_samples_split`, and `min_samples_leaf`. Read about them in the documentation (and in the internet) and see how the performance of the model changes with the change of various parameters. You may want to create a graph of performance from model complexity to see if decision trees overfit easily."
      ],
      "metadata": {
        "id": "83woShjNjfYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "53gvUaAujeel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4"
      ],
      "metadata": {
        "id": "U3Dhh-Q0ZBQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now - the most interesting thing! We can analyze the structure of our fitted decision tree. We have to save the tree into `.dot` file and then we can use the [WebGraphviz](http://www.webgraphviz.com) tool to visualize the tree. You should copy the content of the `.dot` file (saved to the *Files* directory in Colab) to the input area on the [WebGraphviz](http://www.webgraphviz.com)."
      ],
      "metadata": {
        "id": "RCyn5VH5XrPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "# export the decision tree model to a tree_structure.dot file\n",
        "# paste the contents of the file to webgraphviz.com\n",
        "export_graphviz(\n",
        "    dt,\n",
        "    out_file ='tree_structure.dot',\n",
        "    feature_names = X.columns.to_numpy()\n",
        ")"
      ],
      "metadata": {
        "id": "bVm0rSYURkm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a simple linear regression using the same data and take a look into the estimated slopes. Do the conclusions drawn from the linear regression coincide with DT?"
      ],
      "metadata": {
        "id": "33DNE_HfZEgt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}